<html class="notion-html"><head lang="en"><meta charset="utf-8"/><meta content="width=device-width,height=device-height,initial-scale=1,maximum-scale=1,user-scalable=no,viewport-fit=cover" name="viewport"/><title>A study about Vision Transformer</title><meta content="en_US" property="og:locale"/><link href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAABDFJREFUWEe1lltsFGUUx883173Odm9ll7bb7XZvZUu3tl2grb34UIqaJpiIgWwbUbCNWlMJ+qAhkUt8ARMvjZGoL4QHtQSfjAkmREklinGjNBQtRmMaBWmruGy7l9md+cyOzrhLuyTsTudlZ2fO9z+/Od855zsI/ruGRkd1Lv+gXf6/Xr9Puz680fzYGV7WR/mbXYenHD8sxD9O54ROzroBXM1dwLD0ujBoQRg79aj93SKA5rGTJ9IYXiApEvxbB0Cr54AFHjQoqzoETiZ73x8JTCsAD0aj3HVjZ2xFpLx6swMCkV7JeTu+CjqcUh3AiG4/sGfXni8UgOGXX3d+vaT9BQA05hoPNIQ6wIRWoIeaA7PJqDoAA+LEYH/nWwrAs6+drT93bfHX/AN7vRfqAm0SQNQVB6NepzoAR/AHfMHgG3cFcNJJeNybAoxI1QEMNIwHfJ63FYDOffssi2Tk9zu3YL8vDRSlPoCOQXubvA2nFIDR9nZ6umPsfBaLPRqdHoJdg0AQFPTblyHMJVWPgF1P3Of3+78vKsPI2MmhWxim8lFwt2wBi8OtumNZcM0+kI/Ctb7xaDyLh7ZpZvtqGkJWzsiuCYERCxhpygbsrvr8RIfz8iVJQMjFpU4oX/EjnsNk1eIrpdQJRgtae13ZzlctxJBVABLntlfDldhPiOK5Uh70NX7p1W/ghnkmXDEIhfEFBSD9auvDOcPPn5RSpY1WYDgrpBALU7mDwFewDQU+0vcMcIvg4Lz+CNgtFqApquIo3DNAhuVgpv4dICmmYud5AQWAf69tWy47/5mYzZQ8AOQcuO54Ai/QkaIELoeGQrlvFBEMgFaOe08DezNaSkxjqwWSVfF8wDhR9BWTx8e7G+NzH9DEslJr1by2iIf1bCrnY1etQbrk7Ubj7EcKwMgzh5rE70xfCoJglq3dtT7YaKuvONRrE2OY88+7FfH9Dx19c3mJeU42ZhkNhANbEEXSwDgzIOpUno54MrYwM9klAeQHUsvVTTMZPu2RAezWavDVtSBKIwB1/5IqYS8UEUVxfsCaapEABra2+qx491yhQcjXhkx6C1CNCTAEBXBtdKhS97KPbC4HHMnXSAATByd6b047lTkt/yzkbUMmw78A/l4zmE0lO3TZ0dETCY8EsPfAsR3pi/SnhUotwQgyaEwSQHi7EzSsOo2n0MddAQojsO4A0Rcnu4ULK8qsfucWrDvAI0+95NddsXxV2APkJGScadi806b6FpAEJMTk30EpB/ITUapq97fZhLB5VRmyIoSf5FQHoEjiUuLHywNKIxruOXY0l6EPFTWiYARRBAO2Oh2wusqP3sIETGUyMXv7jT4FYGd/axUrDl9E6VyTbFjr8IDL0YAKDs2yS271QvyX0PNnc1Gfz3dEPBuzycbmUDdw/v8hVfQO3g16/vmRHX/8A66tRaH+8auzAAAAAElFTkSuQmCC" rel="shortcut icon" type="image/x-icon"/><link href="/images/logo-ios.png" rel="apple-touch-icon"/><meta content="yes" name="apple-mobile-web-app-capable"/><meta content="telephone=no" name="format-detection"/><meta content="no" name="msapplication-tap-highlight"/><link href="4c758603f1604611142662f0ddecadcb583394b5.css" media="print" rel="stylesheet"/><link href="a76ffb5c236eefaf23cb6b7a42fcd704cce8f55e.css" rel="stylesheet"/><link href="bdf63106d407e81b19ae644945d64ca431d390fd.css" rel="stylesheet" type="text/css"/><meta content="CAI RIZHAO Homepage" name="title"/><meta content="CAI RIZHAO Homepage" name="description"/><link href="https://fonts.googleapis.com/css2?family=Nunito:wght@500;600;700&amp;display=swap" rel="stylesheet"/><link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@500;600;700&amp;display=swap" rel="stylesheet"/><style type="text/css">.notion-page-block > div, .notion-collection_view_page-block > div[data-root] {font-family:Montserrat !important} .notion-header-block div, notion-page-content > notion-collection_view-block > div:first-child div {font-family:Montserrat !important} .notion-sub_header-block div {font-family:Montserrat !important} .notion-sub_sub_header-block div {font-family:Montserrat !important} div:not(.notion-code-block) {font-family:Nunito} </style><link href="e1d809d762eeca23edf0cb31bb17bf3c703085f5.css" rel="stylesheet"/><link href="059fcf7f824d0c026d720886feb4b9138237dc91.png" rel="icon" sizes="16x16" type="image/png"/></head><body class="notion-body"><style>body{background:#fff}body.dark{background:#191919}.initial-loading-spinner{-webkit-animation:rotate 1s linear infinite;animation:rotate 1s linear infinite;-webkit-transform-origin:center center;transform-origin:center center;width:1em;height:1em;opacity:.5;display:block;pointer-events:none}@-webkit-keyframes rotate{0%{-webkit-transform:rotate(0) translateZ(0);transform:rotate(0) translateZ(0)}100%{-webkit-transform:rotate(360deg) translateZ(0);transform:rotate(360deg) translateZ(0)}}@keyframes rotate{0%{-webkit-transform:rotate(0) translateZ(0);transform:rotate(0) translateZ(0)}100%{-webkit-transform:rotate(360deg) translateZ(0);transform:rotate(360deg) translateZ(0)}}</style><style id="scroll-properties">
			::-webkit-scrollbar {
				width: 10px;
				height: 10px;
			}
			::-webkit-scrollbar {
				background: transparent;
			}
			::-webkit-scrollbar-track {
				background: #EDECE9;
			}
			::-webkit-scrollbar-thumb {
				background:#D3D1CB;
			}
			::-webkit-scrollbar-thumb:hover {
				background:#AEACA6;
			}
		</style><div id="notion-app"><div class="notion-app-inner notion-light-theme" style='color: rgb(55, 53, 47); fill: currentcolor; line-height: 1.5; font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; -webkit-font-smoothing: auto;'><div class="notion-cursor-listener" style="width: 100vw; height: 100%; position: relative; display: flex; flex: 1 1 0%; background: white; cursor: text;"><div class="" style="display: flex; flex-direction: column; width: 100%; overflow: hidden;"><div style="max-width: 100vw; z-index: 100; background: white; user-select: none;"><div class="notion-topbar" style="width: 100%; max-width: 100vw; height: 45px; opacity: 1; transition: opacity 700ms ease 0s, color 700ms ease 0s; position: relative;"><div style="app-region: drag; display: flex; justify-content: space-between; align-items: center; overflow: hidden; height: 45px; padding-left: 12px; padding-right: 10px;"><div class="notranslate" style="display: flex; align-items: center; line-height: 1.2; font-size: 14px; app-region: no-drag; height: 100%; flex-grow: 0; margin-right: 8px; min-width: 0px;"><div class="notion-selectable notion-page-block" data-block-id="af8a1016-5700-4006-90e5-12c7cbca5539" style="display: flex; align-items: center; min-width: 0px;"><a href="cai-rizhao.html" rel="noopener noreferrer" style="display: flex; text-decoration: none; user-select: none; cursor: pointer; color: inherit; min-width: 0px;"><div class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 3px; font-size: inherit; line-height: 1.2; min-width: 0px; padding-left: 6px; padding-right: 6px; color: rgb(55, 53, 47);" tabindex="0"><div style="display: flex; align-items: center; min-width: 0px;"><div aria-disabled="true" class="notion-record-icon notranslate notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; display: flex; align-items: center; justify-content: center; height: 20px; width: 20px; border-radius: 3px; flex-shrink: 0; margin-right: 6px;" tabindex="-1"><div style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px;"><div style="height: 14px; width: 14px; font-size: 14px; line-height: 1.1; margin-left: 0px; color: black;"><img alt="ðŸ " aria-label="ðŸ " class="notion-emoji" src="data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" style="width: 100%;
height: 100%;
background: url(f87457017f44d1d87f6d662556796277387c1c28.png) 16.9492% 35.5932%/6000% 6000%"/></div></div></div><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 160px;">CAI Rizhao ï¼ˆè”¡æ—¥é’Š) </div></div></div></a></div><span style="margin-left: 2px; margin-right: 2px; color: rgba(55, 53, 47, 0.5);">/</span><div style="display: flex; align-items: center; flex-shrink: 0;"><div class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 24px; border-radius: 3px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 6px; padding-right: 6px; color: rgb(55, 53, 47);" tabindex="0">...</div><span style="margin-left: 2px; margin-right: 2px; color: rgba(55, 53, 47, 0.5);">/</span></div><div class="notion-selectable notion-collection_view-block" data-block-id="8cf4ad0a-1d36-4608-91ab-e14d0605bc04" style="display: flex; align-items: center; min-width: 0px;"><a href="8cf4ad0a1d36460891abe14d0605bc04.html" rel="noopener noreferrer" style="display: flex; text-decoration: none; user-select: none; cursor: pointer; color: inherit; min-width: 0px;"><div class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 3px; font-size: inherit; line-height: 1.2; min-width: 0px; padding-left: 6px; padding-right: 6px; color: rgb(55, 53, 47);" tabindex="0"><div style="display: flex; align-items: center; min-width: 0px;"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 160px;">Study</div></div></div></a></div><span style="margin-left: 2px; margin-right: 2px; color: rgba(55, 53, 47, 0.5);">/</span><div class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 3px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 6px; padding-right: 6px; color: rgb(55, 53, 47);" tabindex="0"><div aria-disabled="true" class="notion-record-icon notranslate notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; display: flex; align-items: center; justify-content: center; height: 20px; width: 20px; border-radius: 3px; flex-shrink: 0; margin-right: 6px;" tabindex="-1"><div style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px;"><div style="height: 14px; width: 14px; font-size: 14px; line-height: 1.1; margin-left: 0px; color: black;"><img alt="ðŸ“š" aria-label="ðŸ“š" class="notion-emoji" src="data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" style="width: 100%;
height: 100%;
background: url(f87457017f44d1d87f6d662556796277387c1c28.png) 49.1525% 28.8136%/6000% 6000%"/></div></div></div><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 240px;">A study about Vision Transformer</div></div></div><div style="flex-grow: 1; flex-shrink: 1;"></div><div class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 3px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0"><svg class="searchNew" style="width: 14px; height: 14px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden; margin-right: 6px;" viewBox="0 0 17 17"><path d="M6.78027 13.6729C8.24805 13.6729 9.60156 13.1982 10.709 12.4072L14.875 16.5732C15.0684 16.7666 15.3232 16.8633 15.5957 16.8633C16.167 16.8633 16.5713 16.4238 16.5713 15.8613C16.5713 15.5977 16.4834 15.3516 16.29 15.1582L12.1504 11.0098C13.0205 9.86719 13.5391 8.45215 13.5391 6.91406C13.5391 3.19629 10.498 0.155273 6.78027 0.155273C3.0625 0.155273 0.0214844 3.19629 0.0214844 6.91406C0.0214844 10.6318 3.0625 13.6729 6.78027 13.6729ZM6.78027 12.2139C3.87988 12.2139 1.48047 9.81445 1.48047 6.91406C1.48047 4.01367 3.87988 1.61426 6.78027 1.61426C9.68066 1.61426 12.0801 4.01367 12.0801 6.91406C12.0801 9.81445 9.68066 12.2139 6.78027 12.2139Z"></path></svg>Search</div><div class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: flex; align-items: center; justify-content: center; width: 32px; height: 28px; border-radius: 3px;" tabindex="0"><svg class="dots" style="width: 18px; height: 18px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden;" viewBox="0 0 13 3"><g><path d="M3,1.5A1.5,1.5,0,1,1,1.5,0,1.5,1.5,0,0,1,3,1.5Z"></path><path d="M8,1.5A1.5,1.5,0,1,1,6.5,0,1.5,1.5,0,0,1,8,1.5Z"></path><path d="M13,1.5A1.5,1.5,0,1,1,11.5,0,1.5,1.5,0,0,1,13,1.5Z"></path></g></svg></div><div style="flex: 0 0 auto; width: 1px; height: 16px; margin-left: 8px; margin-right: 8px; background: rgba(55, 53, 47, 0.16);"></div><div class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 3px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0"><svg class="notionLogo" style="width: 18px; height: 18px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden; margin-right: 6px;" viewBox="0 0 120 126"><path d="M 20.6927 21.9315C 24.5836 25.0924 26.0432 24.8512 33.3492 24.3638L 102.228 20.2279C 103.689 20.2279 102.474 18.7705 101.987 18.5283L 90.5477 10.2586C 88.3558 8.55699 85.4356 6.60818 79.8387 7.09563L 13.1433 11.9602C 10.711 12.2014 10.2251 13.4175 11.1939 14.3924L 20.6927 21.9315ZM 24.8281 37.9835L 24.8281 110.456C 24.8281 114.351 26.7745 115.808 31.1553 115.567L 106.853 111.187C 111.236 110.946 111.724 108.267 111.724 105.103L 111.724 33.1169C 111.724 29.958 110.509 28.2544 107.826 28.4976L 28.721 33.1169C 25.8018 33.3622 24.8281 34.8225 24.8281 37.9835ZM 99.5567 41.8711C 100.042 44.0622 99.5567 46.2512 97.3618 46.4974L 93.7143 47.2241L 93.7143 100.728C 90.5477 102.43 87.6275 103.403 85.1942 103.403C 81.2983 103.403 80.3226 102.186 77.4044 98.54L 53.5471 61.087L 53.5471 97.3239L 61.0964 99.0275C 61.0964 99.0275 61.0964 103.403 55.0057 103.403L 38.2148 104.377C 37.727 103.403 38.2148 100.973 39.9179 100.486L 44.2996 99.2717L 44.2996 51.36L 38.2158 50.8725C 37.728 48.6815 38.9431 45.5225 42.3532 45.2773L 60.3661 44.0631L 85.1942 82.0036L 85.1942 48.4402L 78.864 47.7136C 78.3781 45.0351 80.3226 43.0902 82.7569 42.849L 99.5567 41.8711ZM 7.5434 5.39404L 76.9175 0.285276C 85.4366 -0.445402 87.6285 0.0440428 92.983 3.93368L 115.128 19.4982C 118.782 22.1747 120 22.9034 120 25.8211L 120 111.187C 120 116.537 118.051 119.701 111.237 120.185L 30.6734 125.05C 25.5584 125.294 23.124 124.565 20.4453 121.158L 4.13735 99.9994C 1.21516 96.1048 0 93.191 0 89.7819L 0 13.903C 0 9.5279 1.94945 5.8785 7.5434 5.39404Z"></path></svg>Try Notion</div></div></div><div style="width: calc(100% - 0px); user-select: none;"></div></div><div class="notion-frame" style="flex-grow: 0; flex-shrink: 1; display: flex; flex-direction: column; background: white; z-index: 1; height: calc(100vh - 45px); max-height: 100%; position: relative; width: 1920px;"><div class="notion-scroller vertical" style="display: flex; flex-direction: column; z-index: 1; flex-grow: 1; position: relative; align-items: center; margin-right: 0px; margin-bottom: 0px; overflow: hidden auto;"><div style="position: absolute; top: 0px; left: 0px;"><div></div></div><div class="whenContentEditable" data-content-editable-root="true" style="caret-color: rgb(55, 53, 47); width: 1920px; display: flex; flex-direction: column; position: absolute; align-items: center; flex-grow: 1; left: 0px; --whenContentEditable--WebkitUserModify:read-write-plaintext-only;"><span style="height: 1px; width: 1px;"></span><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" style="user-select: none; --pseudoSelection--background:transparent; width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0; z-index: 2;"></div><div style="width: 100%; display: flex; justify-content: center; z-index: 3; flex-shrink: 0;"><div style="max-width: 100%; min-width: 0px; width: 900px;"><div style="width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0;"><div style="max-width: 100%; padding-left: calc(96px + env(safe-area-inset-left)); width: 100%;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" style="user-select: none; --pseudoSelection--background:transparent; pointer-events: none;"><div aria-disabled="true" class="notion-record-icon notranslate notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; display: flex; align-items: center; justify-content: center; height: 78px; width: 78px; border-radius: 3px; flex-shrink: 0; position: relative; z-index: 1; margin-left: 3px; margin-bottom: 0px; margin-top: 96px; pointer-events: auto;" tabindex="-1"><div style="display: flex; align-items: center; justify-content: center; height: 78px; width: 78px;"><div style="height: 78px; width: 78px; font-size: 78px; line-height: 1.1; margin-left: 0px; color: black;"><div style="position: relative; width: 78px; height: 78px;"><img alt="ðŸ“š" aria-label="ðŸ“š" class="notion-emoji" src="data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" style="width: 78px;
height: 78px;
background: url(f87457017f44d1d87f6d662556796277387c1c28.png) 49.1525% 28.8136%/6000% 6000%;
opacity: 1;
transition: opacity 100ms ease-out 0s"/><img alt="ðŸ“š" aria-label="ðŸ“š" src="eb670b698f0d46d7f8110e722d6fdd28a7dad339.svg" style="position: absolute; top: 0px; left: 0px; opacity: 0; width: 78px; height: 78px;"/></div></div></div></div><div class="notion-page-controls" style='display: flex; justify-content: flex-start; flex-wrap: wrap; margin-top: 8px; margin-bottom: 4px; margin-left: -1px; color: rgba(55, 53, 47, 0.5); font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; height: 24px; pointer-events: auto;'></div></div><div style="padding-right: calc(96px + env(safe-area-inset-right));"><div><div class="notion-selectable notion-page-block" data-block-id="22956c27-0f2b-4806-96c2-cd184dcaeafc" style="color: rgb(55, 53, 47); font-weight: 700; line-height: 1.2; font-size: 40px; font-family: Lyon-Text, Georgia, ui-serif, serif; cursor: text; display: flex; align-items: center;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Untitled" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">A study about Vision Transformer</div></div><div style="margin-left: 4px;"></div></div></div></div></div><div style="width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0;"><div contenteditable="false" data-content-editable-void="true" style="padding-left: calc(96px + env(safe-area-inset-left)); padding-right: calc(96px + env(safe-area-inset-right)); max-width: 100%; width: 100%;"><div style="width: 100%; font-size: 14px;"><div style="width: 100%; max-width: 100%; padding-top: 8px; padding-bottom: 8px; margin: 0px auto;"><div style="margin: 0px;"><div><div style="display: flex; padding-bottom: 4px; width: 100%;"><div style="display: flex; align-items: center; height: 34px; width: 160px; flex: 0 0 auto; color: rgba(55, 53, 47, 0.65);"><div aria-disabled="true" class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; display: flex; align-items: center; height: 100%; width: 100%; border-radius: 3px; padding: 0px 6px;" tabindex="-1"><div style="display: flex; align-items: center; line-height: 120%; font-size: 14px; min-width: 0px;"><div style="margin-right: 8px;"><svg class="typesCreatedAt" style="width: 16px; height: 16px; display: block; fill: rgba(55, 53, 47, 0.45); flex-shrink: 0; backface-visibility: hidden;" viewBox="0 0 14 14"><path d="M7.01356 14.0001C8.8042 14.0001 10.5958 13.3107 11.9575 11.9324C14.681 9.21201 14.6808 4.7603 11.9571 2.04013C9.23336 -0.680043 4.77573 -0.680043 2.05199 2.04013C0.727519 3.36277 0 5.13301 0 6.99553C0 8.8764 0.727811 10.6285 2.05199 11.9509C3.43207 13.3106 5.22243 14.0001 7.01356 14.0001ZM3.72947 7.00914V8.461V8.65543H3.92382H5.34563H8.2794H8.4738V8.461V5.52541V3.37947V3.18502H8.2794H6.82747H6.63307V3.37947V6.81467H3.92382H3.72947V7.00914ZM1.83985 6.99553C1.83985 5.61698 2.38099 4.32597 3.36061 3.3477C5.36746 1.34337 8.64803 1.34062 10.6585 3.33944C10.6613 3.34219 10.6639 3.34494 10.6668 3.3477C12.676 5.3546 12.6763 8.63642 10.6668 10.6434C8.65705 12.6504 5.37031 12.6504 3.36061 10.6434C2.38099 9.66506 1.83985 8.37408 1.83985 6.99553Z"></path></svg></div><div style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis;">Created</div></div></div></div><div style="display: flex; margin-left: 4px; height: 100%; flex: 1 1 auto; flex-direction: column; min-width: 0px;"><div style="display: flex; align-items: center; margin-left: 4px; height: 100%; flex: 1 1 auto; min-width: 0px;"><div style="display: flex; align-items: center; border-radius: 3px; width: 100%; min-height: 34px; padding: 6px 8px 7px; font-size: 14px; overflow: hidden;"><div style="line-height: 1.5; word-break: break-word; white-space: pre-wrap; pointer-events: none;">August 14, 2021 6:12 AM</div><div style="display: flex; position: absolute; right: 6px; top: 4px;"></div></div></div></div></div></div><div><div style="display: flex; padding-bottom: 4px; width: 100%;"><div style="display: flex; align-items: center; height: 34px; width: 160px; flex: 0 0 auto; color: rgba(55, 53, 47, 0.65);"><div aria-disabled="true" class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; display: flex; align-items: center; height: 100%; width: 100%; border-radius: 3px; padding: 0px 6px;" tabindex="-1"><div style="display: flex; align-items: center; line-height: 120%; font-size: 14px; min-width: 0px;"><div style="margin-right: 8px;"><svg class="typesText" style="width: 16px; height: 16px; display: block; fill: rgba(55, 53, 47, 0.45); flex-shrink: 0; backface-visibility: hidden;" viewBox="0 0 14 14"><path d="M7,4.56818 C7,4.29204 6.77614,4.06818 6.5,4.06818 L0.5,4.06818 C0.223858,4.06818 0,4.29204 0,4.56818 L0,5.61364 C0,5.88978 0.223858,6.11364 0.5,6.11364 L6.5,6.11364 C6.77614,6.11364 7,5.88978 7,5.61364 L7,4.56818 Z M0.5,1 C0.223858,1 0,1.223858 0,1.5 L0,2.54545 C0,2.8216 0.223858,3.04545 0.5,3.04545 L12.5,3.04545 C12.7761,3.04545 13,2.8216 13,2.54545 L13,1.5 C13,1.223858 12.7761,1 12.5,1 L0.5,1 Z M0,8.68182 C0,8.95796 0.223858,9.18182 0.5,9.18182 L11.5,9.18182 C11.7761,9.18182 12,8.95796 12,8.68182 L12,7.63636 C12,7.36022 11.7761,7.13636 11.5,7.13636 L0.5,7.13636 C0.223858,7.13636 0,7.36022 0,7.63636 L0,8.68182 Z M0,11.75 C0,12.0261 0.223858,12.25 0.5,12.25 L9.5,12.25 C9.77614,12.25 10,12.0261 10,11.75 L10,10.70455 C10,10.4284 9.77614,10.20455 9.5,10.20455 L0.5,10.20455 C0.223858,10.20455 0,10.4284 0,10.70455 L0,11.75 Z"></path></svg></div><div style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis;">About</div></div></div></div><div style="display: flex; margin-left: 4px; height: 100%; flex: 1 1 auto; flex-direction: column; min-width: 0px;"><div style="display: flex; align-items: center; margin-left: 4px; height: 100%; flex: 1 1 auto; min-width: 0px;"><div aria-disabled="false" class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: flex; align-items: center; border-radius: 3px; width: 100%; min-height: 34px; padding: 6px 8px 7px; font-size: 14px; overflow: hidden;" tabindex="0"><span style="line-height: 1.5; word-break: break-word; white-space: pre-wrap; pointer-events: none;">Deep learning; Transformer</span><div style="display: flex; position: absolute; right: 6px; top: 4px;"></div></div></div></div></div></div><div><div style="display: flex; padding-bottom: 4px; width: 100%;"><div style="display: flex; align-items: center; height: 34px; width: 160px; flex: 0 0 auto; color: rgba(55, 53, 47, 0.65);"><div aria-disabled="true" class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; display: flex; align-items: center; height: 100%; width: 100%; border-radius: 3px; padding: 0px 6px;" tabindex="-1"><div style="display: flex; align-items: center; line-height: 120%; font-size: 14px; min-width: 0px;"><div style="margin-right: 8px;"><svg class="typesCreatedAt" style="width: 16px; height: 16px; display: block; fill: rgba(55, 53, 47, 0.45); flex-shrink: 0; backface-visibility: hidden;" viewBox="0 0 14 14"><path d="M7.01356 14.0001C8.8042 14.0001 10.5958 13.3107 11.9575 11.9324C14.681 9.21201 14.6808 4.7603 11.9571 2.04013C9.23336 -0.680043 4.77573 -0.680043 2.05199 2.04013C0.727519 3.36277 0 5.13301 0 6.99553C0 8.8764 0.727811 10.6285 2.05199 11.9509C3.43207 13.3106 5.22243 14.0001 7.01356 14.0001ZM3.72947 7.00914V8.461V8.65543H3.92382H5.34563H8.2794H8.4738V8.461V5.52541V3.37947V3.18502H8.2794H6.82747H6.63307V3.37947V6.81467H3.92382H3.72947V7.00914ZM1.83985 6.99553C1.83985 5.61698 2.38099 4.32597 3.36061 3.3477C5.36746 1.34337 8.64803 1.34062 10.6585 3.33944C10.6613 3.34219 10.6639 3.34494 10.6668 3.3477C12.676 5.3546 12.6763 8.63642 10.6668 10.6434C8.65705 12.6504 5.37031 12.6504 3.36061 10.6434C2.38099 9.66506 1.83985 8.37408 1.83985 6.99553Z"></path></svg></div><div style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis;">Property</div></div></div></div><div style="display: flex; margin-left: 4px; height: 100%; flex: 1 1 auto; flex-direction: column; min-width: 0px;"><div style="display: flex; align-items: center; margin-left: 4px; height: 100%; flex: 1 1 auto; min-width: 0px;"><div style="display: flex; align-items: center; border-radius: 3px; width: 100%; min-height: 34px; padding: 6px 8px 7px; font-size: 14px; overflow: hidden;"><div style="line-height: 1.5; word-break: break-word; white-space: pre-wrap; pointer-events: none;">August 14, 2021 7:19 AM</div><div style="display: flex; position: absolute; right: 6px; top: 4px;"></div></div></div></div></div></div></div></div></div><div style="width: 100%; height: 1px; background: rgba(55, 53, 47, 0.09); margin-bottom: 8px;"></div></div></div></div></div><div style="display: flex; width: 100%; justify-content: center; padding-top: 5px;"><div style="max-width: 100%; min-width: 0px; width: 900px;"><div class="notion-page-content" style="flex-shrink: 0; flex-grow: 1; max-width: 100%; display: flex; align-items: flex-start; flex-direction: column; font-family: Lyon-Text, Georgia, ui-serif, serif; font-size: 17px; line-height: 1.6; width: 100%; z-index: 4; padding-bottom: 30vh; padding-left: calc(96px + env(safe-area-inset-left)); padding-right: calc(96px + env(safe-area-inset-right));"><div class="notion-selectable notion-header-block" data-block-id="8441b9e5-4180-4c74-8914-b872e04ea0d2" style="width: 100%; max-width: 1718px; margin-top: 2em; margin-bottom: 4px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 1" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-family: Lyon-Text, Georgia, ui-serif, serif; font-weight: 600; font-size: 1.875em; line-height: 1.3;">Introduction</div></div></div><div class="notion-selectable notion-text-block" data-block-id="1c2b8ec4-444c-4359-b253-1d3998484079" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">Recently, Vision Transformers are increasingly explored. In 2021, some variant vision transformers already achieve better performance than the CNN of similar parameters.</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="844a68b2-e35a-4253-ba09-673fbaa7eeae" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">I have seen some introduction about vision transformer. What I understand so far is that when using a vision transformer, an image is divided into a number of patches. Each patch is processed to a feature embedding (1d vector), and position information is also encoded. Then the embeddings are sent to a Transformer Encoder, which consists of Norm layer, Multi-head attention, MLP.</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="f32f9a58-4131-4f0e-9347-3739c4f88451" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="d6ca09fb-52aa-424f-a649-d541fff68b88" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="2f2ee40f-099a-4c9e-871b-9de1b2dba830" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div style="height: 100%; width: 100%;"><img src="7e8d2d0293cace058a1523161132525d7b526363.png" style="display: block; object-fit: cover; border-radius: 1px; pointer-events: auto; width: 100%;"/></div></div></div></div></div><div contenteditable="false" data-content-editable-leaf="true" placeholder="Write a captionâ€¦" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); font-size: 14px; line-height: 1.4; color: rgba(55, 53, 47, 0.65); padding-top: 6px; padding-bottom: 6px; padding-left: 2px;">Fig 1. The diagram of Vision Transformer (ViT). Image Source: [1]</div></div></div><div class="notion-selectable notion-text-block" data-block-id="2c43b66d-d96a-4b9c-b6d2-6cab40d739eb" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">However, I still have some confuses about some details and here I am studying to Transformer to understand:</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="6cd73f3e-690d-444e-8e40-0987a633aa77" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">1) How patch and position embedding is conducted?</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="71675c72-d71e-449a-8d01-bea42a3c5ea6" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">2) What does Query, Key, Value mean, multi-head means in the Multi-head Attentionï¼Ÿ</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="3f72dbb1-aee0-4a63-bf0b-680c74c58314" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">3) Why using Layer Norm? What is the difference between Layer Norm and Batch Norm</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="9854a1f9-3538-4850-bbe5-257faba130bc" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">4ï¼‰Why MLP can provide locality</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="05b7b050-17e0-473e-97f2-4fd894a01321" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-sub_header-block" data-block-id="4bdec884-769b-4eef-b66e-1ae14d756529" style="width: 100%; max-width: 1718px; margin-top: 1.4em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 2" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-family: Lyon-Text, Georgia, ui-serif, serif; font-weight: 600; font-size: 1.5em; line-height: 1.3;">1) How patch and position embedding is conducted?</div></div></div><div class="notion-selectable notion-text-block" data-block-id="5ddf4286-c221-4451-ad5e-df5f9abfa899" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">The Transformer Encoder uses constant feature vectors of dimension <span class="notion-text-equation-token" contenteditable="false" data-token-index="1" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span></span><span>ï»¿</span></span> through all layers, but the image patch (<span class="notion-text-equation-token" contenteditable="false" data-token-index="3" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>p</mi></msub><mo>âˆˆ</mo><msup><mi>R</mi><mrow><mi>P</mi><mo>Ã—</mo><mi>P</mi><mo>Ã—</mo><mi>C</mi></mrow></msup></mrow><annotation encoding="application/x-tex">x_p \in R^{P\times P \times C}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8252079999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">âˆˆ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">Ã—</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">Ã—</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span></span></span></span></span></span></span></span></span></span><span>ï»¿</span></span>) is a 3D tensor (C is the channel numbers, generally 3 or 1). It is necessary to project the 2D matrix to a 1D vector.</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="4612f67d-7b15-4e2d-a805-5e991750f7f2" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="4c5d55e3-3825-4ca2-96c7-be518f99e4be" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">Reshaping x_p to a 1D vector is straightforward. But a preferred way is to adopt a learnable projection module. For example, a learnable Weight <span class="notion-text-equation-token" contenteditable="false" data-token-index="1" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo>âˆˆ</mo><msup><mi>R</mi><mrow><mi>P</mi><mo>âˆ—</mo><mi>P</mi><mo>âˆ—</mo><mi>C</mi><mo>Ã—</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">E\in R^{P*P*C\times d} </annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">âˆˆ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">âˆ—</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">âˆ—</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="mbin mtight">Ã—</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span><span>ï»¿</span></span>  can be used such that the projection can be expressed by a matrix multiplication <span class="notion-text-equation-token" contenteditable="false" data-token-index="3" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>p</mi></msub><mi>E</mi></mrow><annotation encoding="application/x-tex">x_pE</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span></span><span>ï»¿</span></span>. Together with a class token embedding <span class="notion-text-equation-token" contenteditable="false" data-token-index="5" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{class}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">ss</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>ï»¿</span></span> and a position embedding, <span class="notion-text-equation-token" contenteditable="false" data-token-index="7" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo>âˆˆ</mo><msup><mi>R</mi><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>Ã—</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">E_{pos} \in R^{R(N+1)\times d}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">âˆˆ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mbin mtight">Ã—</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span><span>ï»¿</span></span>, where N is the number of patches. Finally, the  Transformer Encoder's input can be written as </div></div><div style="padding-left: 1.5em; display: flex; flex-direction: column;"><div class="notion-selectable notion-equation-block" data-block-id="45a93801-8774-4c65-92a7-83fc74edd321" style="width: 100%; max-width: 100%; margin-top: 4px; margin-bottom: 0px;"><div contenteditable="false" data-content-editable-void="true" style="display: flex; position: relative;"><div class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; position: relative; width: 100%; border-radius: 3px;" tabindex="0"><div style="display: flex; padding: 4px 8px; width: 100%; flex-direction: column; overflow: auto; color: inherit; fill: inherit;"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mn>0</mn></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mrow><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi></mrow></msub><mo separator="true">;</mo><msubsup><mi>x</mi><mi>p</mi><mn>1</mn></msubsup><mi>E</mi><mo separator="true">;</mo><msubsup><mi>x</mi><mi>p</mi><mn>2</mn></msubsup><mi>E</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msubsup><mi>x</mi><mi>p</mi><mi>N</mi></msubsup><mi>E</mi><mo stretchy="false">]</mo><mo>+</mo><msub><mi>E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">z_0 = [x_{class}; x^1_pE; x^2_pE...x^N_pE] + E_{pos}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.274439em;vertical-align:-0.383108em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">ss</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.891331em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></span></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="0ce86df2-3763-4445-9e48-2156df5b16d3" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">According to Fig.1, what will happen in the Transformer Encoder can be expressed as</div></div><div style="padding-left: 1.5em; display: flex; flex-direction: column;"><div class="notion-selectable notion-equation-block" data-block-id="4aeda54b-c3e5-4013-bbf9-a7840d6e82bd" style="width: 100%; max-width: 100%; margin-top: 4px; margin-bottom: 0px;"><div contenteditable="false" data-content-editable-void="true" style="display: flex; position: relative;"><div class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; position: relative; width: 100%; border-radius: 3px;" tabindex="0"><div style="display: flex; padding: 4px 8px; width: 100%; flex-direction: column; overflow: auto; color: inherit; fill: inherit;"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>z</mi><mi>l</mi><mo lspace="0em" mathvariant="normal" rspace="0em">â€²</mo></msubsup><mo>=</mo><mi>M</mi><mi>S</mi><mi>A</mi><mo stretchy="false">[</mo><mi>L</mi><mi>N</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mrow><mi>l</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>+</mo><msub><mi>z</mi><mrow><mi>l</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mi>l</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mn>2...</mn><mi>L</mi><mspace linebreak="newline"></mspace><msub><mi>z</mi><mi>l</mi></msub><mo>=</mo><mi>M</mi><mi>L</mi><mi>P</mi><mo stretchy="false">[</mo><mi>L</mi><mi>N</mi><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>l</mi><mo lspace="0em" mathvariant="normal" rspace="0em">â€²</mo></msubsup><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>+</mo><msubsup><mi>z</mi><mi>l</mi><mo lspace="0em" mathvariant="normal" rspace="0em">â€²</mo></msubsup><mo separator="true">,</mo><mi>l</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mn>2...</mn><mi>L</mi><mspace linebreak="newline"></mspace><mi>y</mi><mo>=</mo><mi>L</mi><mi>N</mi><mo stretchy="false">(</mo><msubsup><mi>z</mi><mi>L</mi><mn>0</mn></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">z'_l = MSA[ LN(z_{l-1})] + z_{l-1},     l=1, 2 ...L\\
z_l = MLP[LN(z'_l)] + z'_l,     l=1,2 ...L\\
y = LN(z^0_L) </annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.048892em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8018919999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">MS</span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2...</span><span class="mord mathnormal">L</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">[</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8018919999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.048892em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8018919999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2...</span><span class="mord mathnormal">L</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="08f99a5a-3b76-48f5-a0eb-57ddef01c85d" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">where MSA is the Multi-head Self-attention module, LN is Layer Normalization, MLP is Multi-Layer Perceptron, L is the depth of the Transformer encoder. The class token <span class="notion-text-equation-token" contenteditable="false" data-token-index="1" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{class}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">ss</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>ï»¿</span></span> is attached to gather attention information about all patches for the classification.</div></div></div></div><div class="notion-selectable notion-sub_header-block" data-block-id="10fc8cdd-83be-453b-9398-f6d64772cdfa" style="width: 100%; max-width: 1718px; margin-top: 1.4em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 2" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-family: Lyon-Text, Georgia, ui-serif, serif; font-weight: 600; font-size: 1.5em; line-height: 1.3;">2) What do Query (q), Key (k), Value (v) mean, multi-head means in the Multi-head Self Attention (MSA)ï¼Ÿ</div></div></div><div class="notion-selectable notion-text-block" data-block-id="0666aebd-c915-499a-80ef-0b7eb2b0bfe3" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">MSA is based on standard QKV Self Attention [2], multi-head means there are multiple self-attention modules. The QKV self-attention can be represented as </div></div></div></div><div class="notion-selectable notion-equation-block" data-block-id="629a7588-3fb7-4a16-9e2b-8b3f53d1b93c" style="width: 100%; max-width: 1718px; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true" style="display: flex; position: relative;"><div class="notion-focusable" role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; position: relative; width: 100%; border-radius: 3px;" tabindex="0"><div style="display: flex; padding: 4px 8px; width: 100%; flex-direction: column; overflow: auto; color: inherit; fill: inherit;"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>q</mi><mo separator="true">,</mo><mi>k</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">]</mo><mo>=</mo><mi>z</mi><msub><mi>U</mi><mrow><mi>q</mi><mi>k</mi><mi>v</mi></mrow></msub><mo separator="true">,</mo><msub><mi>U</mi><mrow><mi>q</mi><mi>k</mi><mi>v</mi></mrow></msub><mo>âˆˆ</mo><msup><mi>R</mi><mrow><mi>d</mi><mo>Ã—</mo><mn>3</mn><msub><mi>d</mi><mi>h</mi></msub></mrow></msup><mspace linebreak="newline"></mspace><mi>A</mi><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>q</mi><msup><mi>k</mi><mi>T</mi></msup><mi mathvariant="normal">/</mi><msqrt><msub><mi>d</mi><mi>h</mi></msub></msqrt><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>A</mi><mo>âˆˆ</mo><msup><mi>R</mi><mrow><mi>N</mi><mo>Ã—</mo><mi>N</mi></mrow></msup><mspace linebreak="newline"></mspace><mi>S</mi><mi>A</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>A</mi><mi>v</mi></mrow><annotation encoding="application/x-tex">[q, k, v] = zU_{qkv},  U_{qkv} \in R^{d\times 3d_h} \\
A = softmax(qk^T / \sqrt{d_h}), A\in R^{N\times N} \\
SA(z) = Av</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">âˆˆ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8991079999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999998em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">Ã—</span><span class="mord mtight">3</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.256095em;vertical-align:-0.25em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.006095em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.966095em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg height="1.28em" preserveAspectRatio="xMinYMin slice" viewBox="0 0 400000 1296" width="400em"><path d="M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.23390500000000003em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">âˆˆ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.891331em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.891331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">Ã—</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span></span></div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="b1fcac89-4bba-4590-bd06-4620accce1eb" style="width: 394px; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div style="height: 100%; width: 100%;"><img src="2311681403941ecafa433d5acedf193d17b74ecb.png" style="display: block; object-fit: cover; border-radius: 1px; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="6eed3634-3aa2-4186-bc52-ce82540c7975" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div style="height: 100%; width: 100%;"><img src="27cafa04a5c94a72510f66710625ef3ba1409507.png" style="display: block; object-fit: cover; border-radius: 1px; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="583e4ab9-c121-4474-a4ac-43beb5cacd6a" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="858a4601-4adc-4330-9628-8e434501a9bf" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">The meaning of q, k, v confuse me. What do Query, Key, Value mean? Why self-attention is about Query, Key, Value.  The concepts of the Query, Key, Value are from the information retrieval system. For example, if we are using google to search some academic literature, we may type in some query words (Query), such as  "attention, deep learning". After we click "Enter", and then Google shows a page that provides the contents (Values). Each content has its Key (or say, tag, label). The listed contents are shown on the first page of Google because their Keys have high correlations with the Query.</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="49616101-270b-4583-9329-1767db88b2e7" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="edefe056-91ec-4ecb-99ee-d84e5f3d48df" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div style="height: 100%; width: 100%;"><img src="379d04a1c61f65b7a625bd12e64f7227437d7627.png" style="display: block; object-fit: cover; border-radius: 1px; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="59c71a18-242a-4afa-8770-f21dfbe6074c" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="dc899eac-cc1d-4991-a702-18cf2fb5951f" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">Back to the self-attention, according to the description in [2], quoted below</div></div></div></div><div class="notion-selectable notion-quote-block" data-block-id="57e344e1-3fb5-48d7-a405-1a8ffbaef78e" style="width: 100%; max-width: 1718px; margin-top: 4px; margin-bottom: 4px;"><div style="font-size: 1em; padding: 3px 2px; color: inherit; fill: inherit; display: flex;"><div style="border-left: 3px solid currentcolor; padding-left: 14px; padding-right: 14px; width: 100%;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Empty quote" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding-left: 2px; padding-right: 2px;">Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="a64253ca-5384-4d21-ac0a-93d93eae3f25" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">Self-attention is to learn a <span class="notion-enable-hover" data-token-index="1" style="font-weight:600">feature representation</span> from a sequence, where some of the elements in the sequence are given higher attention (weights) in the transformed representation, and the attentions are also learned from the sequence itself. So, how can this be done?</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="ef2bc67a-e3c2-48f6-a08f-a0fdf55038a0" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="45251c5b-8d37-4983-8284-dd779bf1be13" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">In the QKV self-attention, the solution is that, given a sequence of feature embeddings <span class="notion-text-equation-token" contenteditable="false" data-token-index="1" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span></span><span>ï»¿</span></span>, the Value is transformed from the <span class="notion-text-equation-token" contenteditable="false" data-token-index="3" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span></span><span>ï»¿</span></span> to represent the <span class="notion-enable-hover" data-token-index="5" style="font-weight:600">feature representation</span> of the sequence without attention assigned. The attention weights will be calculated by doing a to find information retrieval to get the correlation scores between then Query and Key, which is as what has been discussed above. In other words, the <span class="notion-text-equation-token" contenteditable="false" data-token-index="7" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span></span><span>ï»¿</span></span> is also transformed to Query and Key, by two different learnable weights. The more correlated between then Query and Key, the closer the Value to <span class="notion-enable-hover" data-token-index="9" style="font-style:italic;font-weight:600">What you need.</span></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="5d7fb73d-87ba-4778-ad32-ef120703ff05" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">By calculating a similarity (e.g. inner product, cosine distance) to get a score and multiply it by Value, the Value with Attention is obtained as the final feature representation as the input sequence!</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="15d486fe-61fa-49d0-90a7-474f95051a04" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="450a7c16-a992-4635-bec2-07058d64bec4" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">In short, QKV self-attention is just an implementation. There could be various ways of attention implementation.</div></div></div></div><div class="notion-selectable notion-sub_header-block" data-block-id="86825538-9255-464d-8659-e14e5ca8d20b" style="width: 100%; max-width: 1718px; margin-top: 1.4em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 2" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-family: Lyon-Text, Georgia, ui-serif, serif; font-weight: 600; font-size: 1.5em; line-height: 1.3;">Multi-head attention</div></div></div><div class="notion-selectable notion-text-block" data-block-id="3e9ca826-b8c4-4fdc-be41-9533c6bf5e27" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">Multi-head attention is also from [2], which is to run multiple attention modules in parallel and combine the output results. I would say this is similar to CNN that one head is one channel.</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="770fb334-a002-4555-8c7e-2dca1fc401e9" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-header-block" data-block-id="54e52999-819f-494c-abb0-c23060d46634" style="width: 100%; max-width: 1718px; margin-top: 2em; margin-bottom: 4px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 1" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-family: Lyon-Text, Georgia, ui-serif, serif; font-weight: 600; font-size: 1.875em; line-height: 1.3;">3) Why using Layer Norm, what is the difference from Batch Norm</div></div></div><div class="notion-selectable notion-text-block" data-block-id="a5aa3236-a765-4fc2-93b2-b3dfb5bf1a67" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">Layer normalization is used in both [1] and [2]. I have used batch norm many times in my experiments. This is the first time I came across Layer Norm. What can we benefit from Layer Norm? What is its difference from the Batch Norm?</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="003c38e5-cea2-488e-98d3-c8c2d0e0fe64" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="0026e807-63f5-4ee8-b1de-8cf253aa7568" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;"><span class="notion-enable-hover" data-token-index="0" style="font-weight:600">The motivation of proposing Layer Norm: </span>In training deep models normalizing input to neurons can help reduce the training time by stabilizing the training via regularizing the activities of neurons. Batch Norm is an effective normalization method, which calculates the mean and variance for normalization over the batch data. Thus, Batch Norm relies on the mini-batch size and cannot be directly applied to Recurrent Neural Network (RNN). As such, Layer Norm is proposed to calculate mean and variance without relying on the batch size and thus can be used for RNN.</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="c0f8e63f-bd4e-4b6e-a2c2-28accd2b9a9d" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="df58b0b9-5206-483e-b566-d8020b7358fd" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">I am not going deep into the details about the formulation of Layer Norm and Batch Norm here. I will write another essay to discuss different normalization methods. In short, the motivation of using layer normalization is to boost the training. And the one difference between Layer Norm and Batch Norm is that Layer Norm does not depend on batch size and thus can be used to RNN.</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="35a58053-dd41-4cb0-84c7-6ed37d6b670a" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="bccc8cec-01ce-47ae-87d5-49b76b9fdb77" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div><div class="notion-selectable notion-header-block" data-block-id="088b9c28-6e10-4b6b-b50b-0235e3aeece3" style="width: 100%; max-width: 1718px; margin-top: 2em; margin-bottom: 4px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 1" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-family: Lyon-Text, Georgia, ui-serif, serif; font-weight: 600; font-size: 1.875em; line-height: 1.3;">4ï¼‰Why MLP can provide locality</div></div></div><div class="notion-selectable notion-text-block" data-block-id="3fb15dd2-f071-43fa-a6aa-22c432f1f4ef" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">In [1], it is written that </div></div></div></div><div class="notion-selectable notion-quote-block" data-block-id="72135b1c-110c-4a72-8109-7ed207a8970f" style="width: 100%; max-width: 1718px; margin-top: 4px; margin-bottom: 4px;"><div style="font-size: 1em; padding: 3px 2px; color: inherit; fill: inherit; display: flex;"><div style="border-left: 3px solid currentcolor; padding-left: 14px; padding-right: 14px; width: 100%;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Empty quote" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding-left: 2px; padding-right: 2px;">In ViT, only MLP layers are local and translationally equivariant, while the self-attention layers are global. </div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="33b67186-6aaf-4840-9cb4-223af1981288" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">In my opinion, MLP is a stack of multiple fully connected (FC) layers, and FC layers are known to capture global information. How come MLP layers are local and translationally equivariant as stated in [1]? I am having confusion about it. Any discussion is welcome.</div></div></div></div><div class="notion-selectable notion-header-block" data-block-id="6b6e032d-7b8d-492f-86ec-94b139abd34a" style="width: 100%; max-width: 1718px; margin-top: 2em; margin-bottom: 4px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 1" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-family: Lyon-Text, Georgia, ui-serif, serif; font-weight: 600; font-size: 1.875em; line-height: 1.3;">Reference</div></div></div><div class="notion-selectable notion-text-block" data-block-id="ef99aefc-e6c4-4d16-b14d-8a65399780bb" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">[1] "AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE", ICLR 2021</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="d45dba36-643b-48b6-9897-cf570c1e7d7a" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">[2] "Attention Is All You Need", NIPS 2017</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="91b77aba-5384-4176-8d82-fa9770ea93e3" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">[3] "Layer Normalization", <a class="notion-link-token notion-enable-hover" data-token-index="1" href="https://arxiv.org/abs/1607.06450" rel="noopener noreferrer" style="cursor:pointer;color:inherit;word-wrap:break-word;text-decoration:inherit" target="_blank"><span class="link-annotation-91b77aba-5384-4176-8d82-fa9770ea93e3--1260164872" style="border-bottom:0.05em solid;border-color:rgba(55,53,47,0.4);opacity:0.7">https://arxiv.org/abs/1607.06450</span></a></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="b063984c-1ad3-47db-99fc-dbaaac6424a4" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 0px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; min-height: 1em; color: rgb(55, 53, 47); -webkit-text-fill-color: rgba(55, 53, 47, 0.5);"></div></div></div></div></div></div><div contenteditable="false" data-content-editable-void="true" style="width: 0px;"><div style="display: none; flex-shrink: 0; pointer-events: none; width: 0px; position: absolute; right: 192px; opacity: 0;"><div style="display: flex; flex-direction: column; padding: 5px 16px; width: 340px; flex-shrink: 0; height: 100%; position: relative; pointer-events: none; z-index: 1;"><div style="position: absolute; pointer-events: none; width: 100%; height: 100%; top: -5px; background: linear-gradient(white 0px, rgba(255, 255, 255, 0) 15px);"></div></div></div></div></div><span style="height: 1px; width: 1px;"></span></div><div class="notion-presence-container" style="position: absolute; top: 0px; left: 0px; z-index: 89;"><div></div></div></div></div></div><div class="notion-peek-renderer" style="position: fixed; top: 0px; right: 0px; bottom: 0px; width: 960px; z-index: 109; transform: translateX(960px) translateZ(0px);"></div></div></div></div><textarea style="opacity: 0; pointer-events: none; position: fixed; left: 0px; top: 0px;"></textarea><textarea style="opacity: 0; pointer-events: none; position: fixed; left: 0px; top: 0px;"></textarea><div style="width: env(safe-area-inset-bottom);"></div><iframe aria-hidden="true" referrerpolicy="no-referrer" sandbox="allow-scripts allow-same-origin" src="https://aif.notion.so/aif-production.html" style="position: absolute; opacity: 0; width: 1px; height: 1px; top: 0; left: 0; border: none; display: block; z-index: -1;" tabindex="-1"></iframe><script src="1172e9111a5fb396bcb8a05870b5eabf8abf221c.js" type="text/javascript"></script><script src="09365beecc71279e84d39e7a5c83d6309fe65a5d.js" type="text/javascript"></script></body></html>